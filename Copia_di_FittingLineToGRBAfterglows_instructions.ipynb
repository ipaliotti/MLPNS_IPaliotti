{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipaliotti/MLPNS_IPaliotti/blob/main/Copia_di_FittingLineToGRBAfterglows_instructions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8x2lZsZxK8"
      },
      "source": [
        "# Fitting a line to GRB afterglow photometry\n",
        "\n",
        "This exercise teaches you to fit the simplest model to data: a line, using different methods. \n",
        "\n",
        "Notes: \n",
        "\n",
        "a line is a power law in log-log space. The GRB afterglow is generated by a powerlaw process\n",
        "    \n",
        "we will learn later that a broken powerlaw is a prefer model for the GRB afterglow. But this exercise is about fitting lines: Linear Regression\n",
        "    \n",
        "  **TL;DR: we measure a quantity named magnitude over time, which is an inverse logaritmic measure of brightness of the GRB, and which is expected to change it roughly linearly with the logarithm of time.**\n",
        "\n",
        "_About GRB Afterglows_\n",
        "\n",
        "*Gamma-ray bursts (GRBs) are bright X-ray and gamma-ray flashes observed in the sky, emitted by distant extragalactic sources. They are associated with the creation or merging of neutron stars or black holes; processes which result in an explosive outburst of material moving incredibly close to the speed of light [ref](https://www.mpg.de/16999277/0607-kern-gammarayburst-153865-x#:~:text=It%20was%20this%20afterglow%20emission,the%20form%20of%20synchrotron%20photons). Long after the initial burst of gamma rays has subsided, gamma ray bursts (GRBs) are still observable at less energetic wavelengths. Although no formal definition exists, this smoothly varying, lower energy radiation that may be visible for several days following the GRB itself, is usually referred to as the GRB afterglow.*\n",
        "\n",
        "\n",
        "    \n",
        "  **Details**: *The light that we measure from these explosions changes over time, so we can study its time series. The change in light is exponential, not linear, but if we take the logarithm of the light, that chance may be linear, since the logarithm is the inverse of exponent. The logarithm of the light flux is called magnitude in astronomy. A line is a power law in log-log space. The GRB afterglow is generated by a powerlaw process.*\n",
        "    \n",
        "*It is believed that the afterglow originates in the external shock produced as the blast wave from the explosion collides with and sweeps up material in the surrounding interstellar medium. The emission is synchrotron emission produced when electrons are accelerated in the presence of a magnetic field. The successive afterglows at progressively lower wavelengths (X-ray, optical, radio) result naturally as the expanding shock wave sweeps up more and more material causing it to slow down and lose energy.*\n",
        "\n",
        "*X-ray afterglows have been observed for all GRBs, but only about 50% of GRBs also exhibit afterglows at optical and radio wavelengths [ref](https://astronomy.swin.edu.au/cosmos/G/gamma+ray+burst+afterglow)*\n",
        "\n",
        "  *In reality, the correct model is a  broken powerlaw: the slope of the line \"breaks\" or changes, at some point in time. But this exercise is about fitting lines. But in the end we will use MCMC and find out which model is better*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5-7Wcn5ZxK_"
      },
      "source": [
        "# initial imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:37.972141Z",
          "start_time": "2020-02-13T16:28:37.171220Z"
        },
        "id": "WtF-bBt3ZxLB",
        "outputId": "4a3f5700-159d-4e84-b3e6-ec4255a9af30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "%pylab inline\n",
        "\n",
        "# I have created a stylesheet to define default plot behaviors. \n",
        "# This stylesheet changes the default parameters stored in the dictionary matplitlib.rcParams\n",
        "pl.style.use(\"https://raw.githubusercontent.com/fedhere/MLTSA22_FBianco/master/fbb.mplstyle\")\n",
        "pl.rcParams['font.size'] = 20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbaibtfoZxLG"
      },
      "source": [
        "# Task 1: Read and prepare the input dataset\n",
        "I am reading the data with Pandas. Pandas has excellent utilities for input-output of tabular data and also for time variables. We will use it throughout as our main package to acquire and manipulate data\n",
        "\n",
        "find the link to the *raw* input file on github in the HW1 folder https://github.com/fedhere/MLTSA_FBianco/tree/master/HW1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:37.997047Z",
          "start_time": "2020-02-13T16:28:37.974110Z"
        },
        "id": "TvYjmq0gZxLG",
        "outputId": "683e7687-ede7-402c-fc10-cd047d7d9f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "grbAG = pd.read_csv(...\n",
        "grbAG.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0edc592373e3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    grbAG.head()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxgz88WoZxLJ"
      },
      "source": [
        "## Create the log-time variable\n",
        "\n",
        "We will fit a line in log space. The magnitude column I gave you is the logarithm (base 10) of the flus so that is already available. Create a logarithm base 10 of the time variable\n",
        "\n",
        "(Fitting a line in log-log space corresponds to fitting a powerlaw y=x^a in natural space. Note: we mean logbase 10, use ```numpy.log10()```)\n",
        "\n",
        "If you have trouble with this look at this gist https://gist.github.com/fedhere/42956d318347def627f6ad750c3eee9a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:38.011251Z",
          "start_time": "2020-02-13T16:28:37.998807Z"
        },
        "id": "5Y9ZIboFZxLK",
        "outputId": "9992e50c-8222-4c49-9623-d7b25fd49f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "grbAG[\"logtime\"] = ...\n",
        "grbAG.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-57a34648ef5c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrbAG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logtime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrbAG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grbAG' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdbiJdxjZxLM"
      },
      "source": [
        "## Visualize the data\n",
        "The data are photometric measurements: measurement of flux from an exploding star. The flux is measured in different photometric bands, i.e. within different wavelength range. You can think about this as a filter that would limit the light collected by a camera to a single color, e.g. red, blue, or green. In most all cameras (your phone camera for example) collect data in RGB bands saparately and combine them to create a \"color picture\". Our eyes also perceive color in 3 bands, R, G, B. \n",
        "\n",
        "The information about the photometric band is stored in the variable ```grbAG.filter```. If I wanted to retrieve all magnitudes for filter 'V' I would do ```grbAG.loc[grbAG[\"filter\"] == f, \"mag\"]```.\n",
        "\n",
        "Plot the data with different colors for different photometric bands. \n",
        "\n",
        "Use pl.errorbar to display the uncertainties in the data - if you do not know how to use pl.errorbar you can symply type\n",
        "\n",
        "```pl.errorbar?``` in a cell to retrieve the help"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.errorbar?"
      ],
      "metadata": {
        "id": "OpMjKBznK_6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:38.284324Z",
          "start_time": "2020-02-13T16:28:38.013135Z"
        },
        "id": "8wkMliqUZxLN"
      },
      "source": [
        "#create a figure container and an axis object inside of it\n",
        "ax = pl.figure(figsize=(10,10)).add_subplot(111)\n",
        "    \n",
        "#loop on every filter to plot - this will give differnt colors naturally. \n",
        "#Use pl.errorbar to plot the uncertainties\n",
        "\n",
        "for f in grbAG[\"filter\"].unique():\n",
        "    pl.errorbar(...\n",
        "    \n",
        "\n",
        "# plot the upperlimits as arrows \n",
        "for i in grbAG[grbAG.upperlimit == 1].index:\n",
        "    pl.arrow(grbAG.loc[i].logtime, \n",
        "             grbAG.loc[i].magerr, 0, 2, \n",
        "            head_width=0.05, head_length=0.1, ec='k')\n",
        "\n",
        "# I am going to invert the y axis because the \"magnitude\" measurement is an inverse scale: brighter is smaller\n",
        "pl.gca().invert_yaxis()\n",
        "pl.legend()\n",
        "\n",
        "#Always rememebr you axis labels!!\n",
        "pl.ylabel(\"magnitude\", fontsize=20)\n",
        "pl.xlabel(\"log time (sec after explosion)\", fontsize=20);\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXfRhShVZxLQ"
      },
      "source": [
        "Figure 1: Photometry of the Afterglow of GRB 052505A. All photometry is from the Swift satellite and it is obtained from Table 3 of Blustin et al. 2005 https://arxiv.org/pdf/astro-ph/0507515.pdf. The photometric band for each datapoint is indicated in the legend. Time is relative from the estimated moment of explosion of the stellar progenitor. Upperlimits are indicated by down-pointing arrows. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the data: Remove upper limits\n",
        "This data includes upper limits which I plotted as downward errors. upper and lower limits (technically called \"censored data\" are extremely hard to deal with in modeling). For now, lets just remove them. \n",
        "\n",
        "To remove the upper limits you can \"broadcast\" the data: in pandas that looks like \n",
        "\n",
        "```grbAG.loc[grbAG.upperlimit == 0]```\n",
        "\n",
        "If you do not know how to remove selected rows from a dataframe based on a condition look at this gist https://gist.github.com/fedhere/e9cd67d9dc0357ee547e03a12ceb4719\n",
        "\n",
        "The information about whether the point is an upper limit or a measurement is stored in the variable ```grbAG.upperlimit```. \n"
      ],
      "metadata": {
        "id": "acDR79PxLh0N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER4J4VRKZxLQ"
      },
      "source": [
        "# Task 2: Fit models to data\n",
        "## Task 2a: Solve using the Normal Equation\n",
        "\n",
        "You can use the code I put in the slides for this - you can copy and paste it but you will learn most if you try type it down and make sure you understand it line by line!!\n",
        "\n",
        "It can be shown that the best linear fit to data is given by the equation:  \n",
        "\n",
        "$(X^T \\cdot X)^{-1} \\cdot X^T \\cdot \\vec{y}$\n",
        "\n",
        "The solution is a tuple of 2 parameters: sloper and intercept. Therefore the input has to be Nx2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grbAGnu = grbAG[grbAG.upperlimit == 0] \n"
      ],
      "metadata": {
        "id": "Nm6Jp7oCOJAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones((len(grbAGnu), 1));"
      ],
      "metadata": {
        "id": "8-yQVtqY1DJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:38.293262Z",
          "start_time": "2020-02-13T16:28:38.286493Z"
        },
        "id": "vOAycPfSZxLR"
      },
      "source": [
        "x =  grbAGnu.logtime.values # what is your exogenous variable?\n",
        "\n",
        "X = np.c_[np.ones((len(grbAGnu), 1)),\n",
        "          x]\n",
        "\n",
        "y = grbAGnu.mag.values \n",
        "\n",
        "print(\"shape of the input array X\", X.shape)\n",
        "print(\"shape of the input array y\", y.shape)\n",
        "#note the shape in python is flipped compared to the shape in linear algebra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:38.298369Z",
          "start_time": "2020-02-13T16:28:38.294694Z"
        },
        "id": "F31Kvm9vZxLV"
      },
      "source": [
        "theta_best = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "                                           \n",
        "print (\"best fit parameters from the Normal Equation: \" + \n",
        "       \"intercept {0:.2f}, slope {1:.2f}\".format(*theta_best))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZpRzAmqZxLX"
      },
      "source": [
        "## Task 2b: Fit a line to the data with sklearn LinearRegression\n",
        "\n",
        "The exogenous (independent) variable is ```grbAG.logtime```.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:39.095202Z",
          "start_time": "2020-02-13T16:28:38.299845Z"
        },
        "id": "RIv7Nk8YZxLY"
      },
      "source": [
        "#note: imports should be moved to the top cell - follow PEP8 guidelines\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#sklearn is an object oriented package. You will call the function which will create a model (model selection) then fit it to the data separately (model fitting)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X,y)\n",
        "       \n",
        "#this will create new properties of the model instance: the intercept and coefficients!\n",
        "\n",
        "print (\"best fit parameters from the sklearn LinearRegression(): \" + \n",
        "       \"intercept {:.2f}, slope {:.2f}\".format(lr.intercept_, lr.coef_[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "azIxSebM1RW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YySr_2YbZxLa"
      },
      "source": [
        "## Optional Task 2c: Fit a line to the data (excluding the upper limits) by minimizing an objective function\n",
        "\n",
        "First, choose the L1 metric (see class notes) as the objective function.\n",
        "\n",
        "Use ```scipy.optimize.minimize()``` to minimize it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:39.107377Z",
          "start_time": "2020-02-13T16:28:39.096791Z"
        },
        "id": "40W-FTh3ZxLb"
      },
      "source": [
        "#note: imports should be moved to the top cell - follow PEP8 guidelines\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def line(x, intercept, slope):\n",
        "    \"\"\"\"\"\"\n",
        "    return slope * x + intercept\n",
        "\n",
        "def l1(args, x, y):\n",
        "    a, b = args\n",
        "    return np.sum(np.abs( line(x, a, b) - y)) #see slides!\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "initialGuess = (10, 1) #this can be important, a bad choice can get us stuck in a local minimum. But for this simple problem we can just guess whaetever\n",
        "\n",
        "l1Solution = minimize(l1, initialGuess, args=(x, y))\n",
        "print(l1Solution)\n",
        "print(\"\")\n",
        "print(\"best fit parameters from the minimization of L1: \" + \n",
        "       \"slope {:.2f}, intercept {:.2f}\".format(*l1Solution.x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDxQ3sAkZxLd"
      },
      "source": [
        "\n",
        "## Optional task 2d: Fit a line to the data (excluding the upper limits) by minimizing an objective function that accounts for the measurements uncertainties\n",
        "\n",
        "Since the data has uncertainty, choose the Pearson's $\\chi^2$ (chi squared) function as your objective function. The $\\chi^2$ is the distance between prediction and truth, divided by the uncertainty (sigma squares) see slides or see slides or https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#:~:text=10%20References-,Definition,differs%20from%20a%20theoretical%20distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:39.119755Z",
          "start_time": "2020-02-13T16:28:39.108888Z"
        },
        "id": "yY_ST3NmZxLe"
      },
      "source": [
        "def chi2(args, x, y, s):\n",
        "    a, b = args\n",
        "    return np.sum(((line(x, a, b) - y)**2) /  s**2)\n",
        "    #see notes\n",
        "\n",
        "s = grbAGnu.magerr.values \n",
        "# assign the uncertainties to s. Its the column names \"magerr\"\n",
        "\n",
        "initialGuess = (10, 1)\n",
        "\n",
        "chi2Solution = minimize(chi2, initialGuess, args=(x, y, s))\n",
        "\n",
        "print(chi2Solution)\n",
        "print(\"\")\n",
        "print(\"best fit parameters from the minimization of the chi squared: \" + \n",
        "       \"slope {:.2f}, intercept {:.2f}\".format(*chi2Solution.x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPGyuXwZxLg"
      },
      "source": [
        "# Task 3: Plot all the solutions\n",
        "\n",
        "To do this best, you can create a function that uses the parameters you input and plots a line. Add a legend that describes which line corresponds to what.\n",
        "\n",
        "If you do not know how to define a function look here. https://gist.github.com/fedhere/babc8d20533acb9288caf097138825bc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-13T16:28:39.528853Z",
          "start_time": "2020-02-13T16:28:39.121363Z"
        },
        "id": "jv1jKwD-ZxLg"
      },
      "source": [
        "def plotline(x, intercept, slope, legend=None, symbol='-', ax=ax):\n",
        "    ax.plot(x, line(x, intercept, slope), ls=symbol, label=legend)\n",
        "    \n",
        "newx = np.array([2, 6])\n",
        "ax = pl.figure(figsize=(10,10)).add_subplot(111)\n",
        "\n",
        "\n",
        "for f in grbAG[\"filter\"].unique():\n",
        "    pl.errorbar(grbAG.loc[grbAG[\"filter\"] == f].logtime,   \n",
        "             grbAG[grbAG[\"filter\"] == f].mag, fmt='o', alpha=0.5,\n",
        "             yerr=grbAG[grbAG[\"filter\"] == f].magerr, label=f)\n",
        "    \n",
        "\n",
        "# plot the upperlimits as arrows \n",
        "for i in grbAG[grbAG.upperlimit == 1].index:\n",
        "    pl.arrow(grbAG.loc[i].logtime, \n",
        "             grbAG.loc[i].magerr, 0, 2, \n",
        "            head_width=0.05, head_length=0.1, ec='k')\n",
        "# plot the datapoints as above as errorbars\n",
        "# plot the upperlimits as arrows (see above)\n",
        "\n",
        "#plot the models\n",
        "\n",
        "#normal equation\n",
        "plotline(newx, *theta_best, ax=ax, legend=\"Normal Eq\")\n",
        "         \n",
        "#sklearn\n",
        "plotline(newx, lr.intercept_, lr.coef_[1], ax=ax, legend=\"sklearn\", symbol='--')\n",
        "         \n",
        "#minimize L1\n",
        "plotline(newx, *l1Solution.x, ax=ax, legend=\"L1\", symbol='-.')\n",
        "\n",
        "#minimize L2\n",
        "plotline(newx, *l2Solution.x, ax=ax, legend=\"L2\", symbol='--')\n",
        "\n",
        "\n",
        "#minimize chi2\n",
        "plotline(newx, *chi2Solution.x, ax=ax, legend=\"chi2\", symbol='-')\n",
        "\n",
        "        \n",
        "pl.legend()\n",
        "\n",
        "#with the LinearRegression object I can also do\n",
        "#pl.plot(grbAG.logtime, lr.predict(np.c_[np.ones((len(grbAG), 1)), grbAG.logtime]), 'k-')\n",
        "\n",
        "pl.xlim(1.5, 6.5)\n",
        "pl.ylabel(\"magnitude\", fontsize=20)\n",
        "pl.gca().invert_yaxis()\n",
        "\n",
        "pl.xlabel(\"log time (sec after explosion)\", fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqvaf7DjZxLj"
      },
      "source": [
        "Figure 2: Same as Figure 1, but with linear regression models plotted. The models correspond to the best fit line to the data (excluding upper limits) calculated analytically by solving the normal equation, by solving the fit analysitcally with sklearn.LinearRegression(), and by minimizing the objective functions L1 and Chi squared. The models are indicated in the legend."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML we reserve some data to test our restuls."
      ],
      "metadata": {
        "id": "ShEEtMGE1wkI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHz7WsBHZxLl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x, y, s, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chi2Solution = minimize(chi2, initialGuess, args=(x_train, y_train, s_train)) #train on the training set\n",
        "\n",
        "print(chi2Solution)\n",
        "print(\"\")\n",
        "print(\"best fit parameters from the minimization of the chi squared: \" + \n",
        "       \"slope {:.2f}, intercept {:.2f}\".format(*chi2Solution.x))"
      ],
      "metadata": {
        "id": "sIxf5DQk2ACz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2Solution = minimize(l2, initialGuess, args=(x_train, y_train)) #train on the training set\n",
        "\n",
        "print(chi2Solution)\n",
        "print(\"\")\n",
        "print(\"best fit parameters from the minimization of the chi squared: \" + \n",
        "       \"slope {:.2f}, intercept {:.2f}\".format(*chi2Solution.x))"
      ],
      "metadata": {
        "id": "3szsHzMf2IFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usiamo L2 come diagnostica del successo del modello\n",
        "l2(chi2Solution.x, x_test, y_test), l2(l2Solution.x, x_test, y_test)"
      ],
      "metadata": {
        "id": "U_VvbC3U2Maw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's fit a line with MCMC\n"
      ],
      "metadata": {
        "id": "PH6Vlu1-2VuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emcee"
      ],
      "metadata": {
        "id": "Vr_h2UIv2Wc_",
        "outputId": "c745bf06-caec-48ec-e856-4ddf4016dfcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emcee\n",
            "  Downloading emcee-3.1.4-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from emcee) (1.22.4)\n",
            "Installing collected packages: emcee\n",
            "Successfully installed emcee-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emcee"
      ],
      "metadata": {
        "id": "NDLe2PKw2b5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_prior(theta):\n",
        "  slope, intercept = theta\n",
        "  if slope > 0 and intercept > 0:\n",
        "    return 0 #if within prior return 0\n",
        "  return -np.inf"
      ],
      "metadata": {
        "id": "rxT2JaNe2fJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(theta, x, y, yerr):\n",
        "  \"\"\" this is where the model goes: the likelihood can be a simple gaussian likelihood \n",
        "  (i.e.) the log likelihood is the chi squared!\n",
        "  theta: array-like, slope and intercept\n",
        "  x arra-like: exogenous variable\n",
        "  y arra-like: endogenous variable\n",
        "  yerr arra-like: uncertainty on endogenous variable\"\"\"\n",
        "  slope, intercept = theta\n",
        "  #chi2 likelihood : (data-model)**2 / uncertainty **2\n",
        "  return -np.sum(((y - line(intercept, slope, x))**2) / yerr**2)"
      ],
      "metadata": {
        "id": "oOz_A6YM2f3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_probability(theta, x, y, yerr): \n",
        "  #log posterior\n",
        "  \"\"\" the posterior probability\n",
        "  P(model | data) ~ P(data | model) * P(model) = likelihood * prior\n",
        "\n",
        "  theta: array-like, slope and intercept\n",
        "  x arra-like: exogenous variable\n",
        "  y arra-like: endogenous variable\n",
        "  yerr arra-like: uncertainty on endogenous variable\"\"\"\n",
        "  lp = log_prior(theta)\n",
        "  if not np.isfinite(lp):\n",
        "    return -np.inf\n",
        "  return lp + log_likelihood(theta, x ,y ,yerr)"
      ],
      "metadata": {
        "id": "wlvTNd1O2iRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ig = [10,1] #initial guess\n",
        "ndim = len(ig) #the dimension of the parameter space\n",
        "nwalkers = 32 #number of walkers (independent optimization paths)\n",
        "pos = np.array(ig) + 1e-4 * np.random.randn(nwalkers, ndim) # the starting position for each walker, close to the initial guess\n",
        "\n",
        "pos.shape"
      ],
      "metadata": {
        "id": "4xE82F662kg7",
        "outputId": "00cd6dd2-8895-458e-abc8-52662a2be101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=(x, y, s)) #create the emcee obkect\n",
        "sampler.run_mcmc(pos, 5000, progress=True); #run the emcee for 5000 steps\n",
        "samples = sampler.get_chain() #get the path of each walker\n",
        "\n",
        "flat_samples = sampler.get_chain(discard=200, thin=15, flat=True) #throw away burn in phase\n",
        "\n",
        "mcmc = np.zeros((ndim, 3))\n",
        "for i in range(ndim):\n",
        "  mcmc[i] = np.percentile( flat_samples[:,i], [16, 50, 84]) #extract the interquartile range and median solution for each parameter\n",
        "mcmc"
      ],
      "metadata": {
        "id": "yyXth5Vh2mx6",
        "outputId": "4f8544aa-a0d2-462b-cd5c-86b9395d2ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3a0853fd3d6b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memcee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnsembleSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnwalkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#create the emcee obkect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m#run the emcee for 5000 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get the path of each walker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflat_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#throw away burn in phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corner"
      ],
      "metadata": {
        "id": "Sai1S5OU2qje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the posterior\n",
        "import corner\n",
        "pl.rcParams[\"font.size\"]= 13\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=[\"intecept\", \"slope\"], truths=mcmc[:,1]);\n"
      ],
      "metadata": {
        "id": "QIKd-yh22rLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the chais\n",
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = sampler.get_chain()\n",
        "\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "axes[-1].set_xlabel(\"step number\");"
      ],
      "metadata": {
        "id": "Ptwd_MhC2wdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcmc = np.zeros((ndim, 3))\n",
        "for i in range(ndim):\n",
        "  mcmc[i] = np.percentile( flat_samples[:,i], [16, 50, 84])\n",
        "mcmc"
      ],
      "metadata": {
        "id": "PbK0kZaV2xkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now try a broken power law with MCMC\n",
        "\n",
        "New model: \n",
        "\n",
        "$F = \\mathrm{flux}$\n",
        "\n",
        "$t =  \\mathrm{time}$\n",
        "\n",
        "$T_b =  \\mathrm{Time~of~break}$\n",
        "\n",
        "$a_1, a_2, T_b, b:  \\mathrm{model parameters}$\n",
        "\n",
        "\n",
        "$F=\\frac{F_0}{ \\frac{t}{T_b}^{-a1} + \\frac{t}{T_b}^{-a2}}$\n",
        "\n",
        "\n",
        "$b - log_{10}((\\frac{t}{T_b})^{-a1} + (\\frac{t}{T_b})^{-a2}) $\n",
        "\n"
      ],
      "metadata": {
        "id": "D-T6yykL20Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pars = [\"b\", \"Tb\", \"a1\", \"a2\"]\n",
        "def bpl(theta, t):\n",
        "  b, Tb, a1, a2  = theta \n",
        "  return b-np.log10((t/Tb)**(-a1) + (t/Tb)**(-a2))"
      ],
      "metadata": {
        "id": "hj0JQ_Kr2xhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_nolog = grbAGnu.time.values"
      ],
      "metadata": {
        "id": "pN1Shki92xe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_prior(theta):\n",
        "  b, Tb, a1, a2  = theta \n",
        "  if Tb<10**6 and a1>0 and a2>0 and Tb>0: #non ha senso Tb maggiore dell'intervallo tra i miei punti\n",
        "    return 0 \n",
        "  return -np.inf\n",
        "  "
      ],
      "metadata": {
        "id": "ZVXoecbU2xY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(theta, x, y, yerr):\n",
        "  b, Tb, a1, a2  = theta \n",
        "  return -np.sum(((y - bpl(theta,x_nolog))**2) / yerr**2)\n",
        "  "
      ],
      "metadata": {
        "id": "qF-kVH5N2xQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nll = lambda *args: -log_likelihood(*args)\n",
        "ig = [12, 2000, 2.5, 2.5]\n",
        "\n",
        "soln = minimize(nll, ig, args=(x_nolog, y, s))\n",
        "soln"
      ],
      "metadata": {
        "id": "W-hdKerI3MGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initial guess\n",
        "ig = soln.x\n",
        "nwalkers = 32\n",
        "ndim = len(ig)\n",
        "\n",
        "pos = np.array(ig) + 1e-4 * np.random.randn(nwalkers, ndim)\n",
        "\n",
        "pos.shape"
      ],
      "metadata": {
        "id": "boc1z2Qz3OJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=(x_nolog, y, s))\n",
        "sampler.run_mcmc(pos, 20000, progress=True);\n",
        "samples = sampler.get_chain()\n",
        "\n",
        "flat_samples = sampler.get_chain(discard=200, thin=15, flat=True)\n",
        "\n",
        "mcmc = np.zeros((ndim, 3))\n",
        "for i in range(ndim):\n",
        "  mcmc[i] = np.percentile( flat_samples[:,i], [16, 50, 84])\n",
        "mcmc"
      ],
      "metadata": {
        "id": "TOVIeM593iQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pars"
      ],
      "metadata": {
        "id": "Z1UPKBxN3kIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bfig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = sampler.get_chain()\n",
        "\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "axes[-1].set_xlabel(\"step number\");import corner\n",
        "pl.rcParams[\"font.size\"]= 13\n",
        "fig = corner.corner(\n",
        "    flat_samples, labels=pars, truths=mcmc[:,1]);"
      ],
      "metadata": {
        "id": "H23XHBMG3mUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
        "samples = sampler.get_chain()\n",
        "\n",
        "for i in range(ndim):\n",
        "    ax = axes[i]\n",
        "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
        "    ax.set_xlim(0, len(samples))\n",
        "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
        "\n",
        "axes[-1].set_xlabel(\"step number\");"
      ],
      "metadata": {
        "id": "KcbIxqQr3pwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotline(x, intercept, slope, legend=None, symbol='-', ax=ax):\n",
        "    ax.plot(x, line(x, intercept, slope), ls=symbol, label=legend)\n",
        "\n",
        "\n",
        "newx = np.array([2, 6])\n",
        "ax = pl.figure(figsize=(10,10)).add_subplot(111)\n",
        "\n",
        "\n",
        "for f in grbAG[\"filter\"].unique():\n",
        "    pl.errorbar(grbAG.loc[grbAG[\"filter\"] == f].logtime,   \n",
        "             grbAG[grbAG[\"filter\"] == f].mag, fmt='o', alpha=0.5,\n",
        "             yerr=grbAG[grbAG[\"filter\"] == f].magerr, label=f)\n",
        "    \n",
        "\n",
        "# plot the upperlimits as arrows \n",
        "for i in grbAG[grbAG.upperlimit == 1].index:\n",
        "    pl.arrow(grbAG.loc[i].logtime, \n",
        "             grbAG.loc[i].magerr, 0, 2, \n",
        "            head_width=0.05, head_length=0.1, ec='k')\n",
        "# plot the datapoints as above as errorbars\n",
        "# plot the upperlimits as arrows (see above)\n",
        "\n",
        "#plot the models\n",
        "\n",
        "\n",
        "#minimize chi2\n",
        "plotline(newx, *chi2Solution.x, ax=ax, legend=\"chi2\", symbol='-')\n",
        "newx2 = np.linspace(grbAG.logtime.min(), grbAG.logtime.max(), 100)\n",
        "ax.plot(newx2, bpl(mcmc[:,1], 10**newx2), label=\"BPL\")\n",
        "ax.axvline(np.log10(mcmc[1,1]), color='k')\n",
        "pl.legend()\n",
        "\n",
        "#with the LinearRegression object I can also do\n",
        "#pl.plot(grbAG.logtime, lr.predict(np.c_[np.ones((len(grbAG), 1)), grbAG.logtime]), 'k-')\n",
        "\n",
        "pl.xlim(1.5, 6.5)\n",
        "pl.ylabel(\"magnitude\", fontsize=20)\n",
        "pl.gca().invert_yaxis()\n",
        "\n",
        "pl.xlabel(\"log time (sec after explosion)\", fontsize=20);"
      ],
      "metadata": {
        "id": "m2sYZ9Ou3qga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}